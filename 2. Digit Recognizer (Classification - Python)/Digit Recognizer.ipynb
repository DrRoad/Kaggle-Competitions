{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle - Digit Recognizer - Deep learning\n",
    "\n",
    "## Classify handwritten digits using the famous MNIST data\n",
    "\n",
    "Get the data here: https://www.kaggle.com/c/digit-recognizer \n",
    "\n",
    "\n",
    "\n",
    "### 1. Tflearn\n",
    "\n",
    "#### Train from the datasets.mnist\n",
    "Main source: https://github.com/tflearn/tflearn/blob/master/examples/images/convnet_mnist.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import tflearn\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.estimator import regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/gzip.py:274: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "  return self._buffer.read(size)\n",
      "//anaconda/lib/python3.5/site-packages/tflearn/datasets/mnist.py:52: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "  data = data.reshape(num_images, rows, cols, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "## TEST with the mnist data set\n",
    "# Data loading and preprocessing\n",
    "import tflearn.datasets.mnist as mnist\n",
    "\n",
    "X, Y, testX, testY = mnist.load_data(one_hot=True)\n",
    "X = X.reshape([-1, 28, 28, 1])\n",
    "testX = testX.reshape([-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 8600  | total loss: \u001b[1m\u001b[32m0.42696\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 010 | loss: 0.42696 - acc: 0.9239 | val_loss: 0.11866 - val_acc: 0.9701 -- iter: 55000/55000\n",
      "Training Step: 8600  | total loss: \u001b[1m\u001b[32m0.42696\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 010 | loss: 0.42696 - acc: 0.9239 | val_loss: 0.11866 - val_acc: 0.9701 -- iter: 55000/55000\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Building convolutional network\n",
    "network = input_data(shape=[None, 28, 28, 1], name='input')\n",
    "network = conv_2d(network, 32, 3, activation='relu', regularizer=\"L2\")\n",
    "network = max_pool_2d(network, 2)\n",
    "network = local_response_normalization(network)\n",
    "network = conv_2d(network, 64, 3, activation='relu', regularizer=\"L2\")\n",
    "network = max_pool_2d(network, 2)\n",
    "network = local_response_normalization(network)\n",
    "network = fully_connected(network, 128, activation='tanh')\n",
    "network = dropout(network, 0.8)\n",
    "network = fully_connected(network, 256, activation='tanh')\n",
    "network = dropout(network, 0.8)\n",
    "network = fully_connected(network, 10, activation='softmax')\n",
    "network = regression(network, optimizer='adam', learning_rate=0.01,\n",
    "                     loss='categorical_crossentropy', name='target')\n",
    "\n",
    "# Training\n",
    "## 10 Epoch \n",
    "model = tflearn.DNN(network, tensorboard_verbose=0)\n",
    "model.fit({'input': X}, {'target': Y}, n_epoch=10,\n",
    "           validation_set=({'input': testX}, {'target': testY}),\n",
    "           snapshot_step=100, show_metric=True, run_id='convnet_mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save a model (The most important is to save the learned weights, that what the model learn from the trainning)\n",
    "model.save('model.tflearn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization in TensorBoard\n",
    "\n",
    "While writing a Tensorflow model and adding tensorboard summaries isn't very practical, TFLearn has the ability to self managed a lot of useful logs. Currently, TFLearn supports a verbose level to automatically manage summaries:\n",
    "\n",
    "Type: $ tensorboard --logdir='/tmp/tflearn_logs' in your terminal.\n",
    "\n",
    "Then you can visualize your model evolution here: http://0.0.0.0:6006 \n",
    "\n",
    "Read more: https://www.tensorflow.org/how_tos/summaries_and_tensorboard/\n",
    "\n",
    "![title](img/Graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/Accuracy.png)\n",
    "![title](img/Loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the learned weights\n",
    "\n",
    "![title](img/Weight.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Network for MNIST dataset classification task.  \n",
    "**References:**  \n",
    "   * Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, 86(11):2278-2324, November 1998.  \n",
    "\n",
    "**Links:**  \n",
    "    [MNIST Dataset] http://yann.lecun.com/exdb/mnist/  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tensorflow\n",
    "\n",
    "Now starting with the csv from Kaggle.\n",
    "\n",
    "Sources: https://www.kaggle.com/mbeierling/digit-recognizer/my-first-nn-using-tensorflow - https://www.kaggle.com/mbeierling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_size => 784\n",
      "image_width => 28\n",
      "image_height => 28\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztXelW21qzbM9zGJKc7/3f7yQEMB4xvj/OLaVU7i3JxjYC\nda21l2QwHoRq99zd2u/3FggEmoX2R3+AQCBwfQTxA4EGIogfCDQQQfxAoIEI4gcCDUQQPxBoIIL4\ngUAD0b3Ce0SiQCDwcWh5PwyJHwg0EEH8QKCBCOIHAg1EED8QaCCC+IFAAxHEDwQaiCB+INBABPED\ngQYiiB8INBBB/ECggQjiBwINRBA/EGgggviBQAMRxA8EGoggfiDQQATxA4EGIogfCDQQQfxAoIEI\n4gcCDUQQPxBoIIL4gUADEcQPBBqIIH4g0EAE8QOBBiKIHwg0EEH8QKCBCOIHAg1EED8QaCCC+IFA\nAxHEDwQaiCB+INBABPEDgQYiiB8INBBB/ECggQjiBwINRBA/EGgggviBQAMRxA8EGoggfiDQQATx\nA4EGIogfCDQQQfxAoIHofvQHCJwX+/3+4n+D53tHb729vWXndUGr1cqOfM4/Sy1+btF5nRHEbwiU\ndEpa7zmp1wGZQWicY72+vtput7PX19fc+W63s7e3t/N+sSMB8rbbbWu327lzrE6nk1z4G/ydtyl8\nBgTxvzg8YquE1vOy19vtdrn19vaWnW+3W9tsNsm12+0u8C2ro9VqFRK72+1ar9dLrm63m9wwgviB\nWiAl1VNLn+sBEj21NpuNLZdLW61W7vH19fVyX7gC2u22dbtdd4Hcg8HAhsOhDQaD3IJGA8nf6XSy\n69VqtWy/338a8gfxvyiq2OFse+sGkAKkemotl0tbLBb28vLiru12e9kv/v9IfY9Op5MRvN/vH0j0\n4XBoo9HIRqORjcdjG41G9vr6mpko+/3eut2udTqd7DUh/T8TgvhfGCnSM+HZTq9KfEh2Xuv12jab\njS0WC3t+franp6fcEeebzebi35uh36fb7Vq/37d+v2+DwSB37Pf7NhqNbDqd2mQysc1mkyM91Hm9\nTq1WK9MEPguC+F8QKbvek/bqpCsj/uvra2bHr9drW6/XtlqtsvP5fG5//vxx1+Pjo61Wq4t+9xTw\nvbrdbqbGD4fD3PlgMLDJZGKr1colPex7Vu/xuG5RizIE8b8oqtj16o2vQnxW9dfr9YEd//T0ZH/+\n/LHfv3/br1+/7Pfv37nz5XJ56a+exH6/t16vl6nyrNbj8Ww2OyA9nH79ft+63f8ow559tvU/C4L4\nnwzeDaYk9wjNiz3xeqwi8ZfLpeu4Wy6XGfF5PTw8ZMdLS/yyz9/tdm21WtlqtbLRaJRpLHjM10Dj\n+u12297e3mwwGNjr66sNBoPcczudTmlMvy7OvyD+J0RROO7t7c22223O066POa6OVTXO/vr6eqDi\n8xGq/tPTk728vNhyucwk6DWkImzwImCTg68C4Tizv9IdJMY1xXOn02nO8TcajXKaQSoxqC6EB4L4\nnxQprzwTk51u+JluArqqEF8deurcg0Pv5eUls5eraBPnQhH5cZ1AfCb9fr8/eMwbBDSbyWSSXUv2\nAfR6vVwyj8b260T+IP4nhOeNhxrPtre3mPxeOK6M+F44b7PZZOeQ+gjfXVviA0Xk5wxDkBTXEFBJ\nz+bMzc3NgeMP8X9IfTj9eCMJ4gdORplzDuTjWDoTERIYZNXzKsQv0hig8rMf4NoSH/DIzxIfRMS1\nxGdMkR4bGcwiszzpcQ2Y9PgcdSK9WRD/04KJz845lvjz+fwgnr5YLFwVHceylFpOz62SsovXvbbE\nBzzy4/Oa5Unf6XQOvgdIj5DfarU68PYPBgMbjUa23W6t1+u5Mf66ZfYF8T8hPKnPN+x6vbbFYpER\nnz3sLy8vbvwdqyyltkjbYBXaK9T5qJAXk59VeiY9VHLNU0B2HxJ8EJVAXH8wGNh4PM5MKN042ZSo\nE4L4nxAp0uOmVeI/PDxk8fTn5+csfOWtMonvJQTp41Sy0Efe/Ep+aCrqfYcUX6/Xbj7/er3Oqffj\n8Tjn7OONk239uiGIXzN4Nimfs0qvobrtdntg23O67OPjoz09PeVi16cS/1ScouqqZ7ysVj616ejm\n421GvIl6lXvtdtsmk4nN53ObTqe2WCxy/ox+v2+73S6n8kPdr1M+fxC/hiiSpqyKek46tuufn58z\nxx5uUA71YdP4SDU8hVSDDGTKIdaOI87NzM1V4DwFvq44ppyA2DxarVZug4UpwEVJ8/nc2u12Zhb0\n+/3Mrq8T6c2C+LWEl0/Pnma1yzVXHpKdvfkgvnr1QYYq6brXQpFER/ksiMXnIJoXreCNrkgDwJEJ\nz79X4rPHfz6fW6fTyUJ9TPput1ub62sWxK8dypxnsOFT9e4s8efzuc3nc1ssFjniI+bOjreP7ozD\n8JJgcIRDDQU2uszswHxB/TzA11edfZ5/gv+OiY9rjusL4rMGBQ2lblpVEL+G4JtO8+lZxeSbDktL\nYTmRBsRXj3sdnG8K7XCDx3CqjUYjm0wmNh6PMwfbeDy2/X6fux6wy80sIx879UBs9W14PgKo+yrx\noeoPh8NcwQ4kfa/Xq9XGahbEry20qAZkZYnvJemA+FD1WeJDAnIkgDeVOkBVe21vxXHzyWRis9nM\nptOpzWYzm81mtt/vbT6fZ5V08KrvdrssT0HVd34/3gB5g8Dz+H/AGzCI3+12c+o9TJE6mVJmQfza\nQdVMjYXDXmXiQ62HlOfl2fjqN6ibxPfUfKjrKI9l4t/c3GRrv99bv9/Png/SI6MRGx7A0px/xufs\naFRVH/8HtOfitlzQTvCedbm+ZkH8WsKL0WsdvDqVIOXZm4/Fqv5ms3G92XW6Kc0Ou+EqmdAp59u3\nb3Z7e2v39/d2d3dn+/0+k7pmliN9r9fLxdlTTjz+HT4L4Hn1uYMPN+wcDAa52v46XeMg/pWRIh3O\nWapzAQyOqH5LLSY71HutzKs7UqTnhhhw5o3H40zVh8RPpdz2+/1czz9c93a7XZi/wITVhCkN8bHj\ntI4REyCIf2Uc47X3QnbwHrNUZ1VfY/Z1lTgpeM0vWH0G+bV3Hjz9+/0+11KLpTEaapodSvtjUmv1\nMxYlE9UVQfwPgBa5cKKJtrPSVdTBVr33LOU/C/HNDsN5Hum5FTaH9/b7fe5nSn6YOljI0z+WqEpu\nj/R13gSC+FdGKu0W56vVKpPaTGg8hjTnVFH+GWsKmqTzWZBy7unQC0/im1lO4nNyDzYLlvaIsZ9K\nzqpSv27kD+JfGZyB57WphiqvKjyOKKtN5dqzfwB2Z13TcouQsvNV4oPUnMCTUvVBfi7D1TFYx36+\nKquOCOJ/AFjiwwEFKc2xeKTe8krV0+McEt5rqfVZiF/k3NOBGCzxR6NRZuPrFBwemsEOulPGX6VU\nfG8TqSv5g/hXhqr6HBZC2yqQ3utNv1gskq2zmOTsUf5Mqr7n3CuT+Gzjm6VVfUj83W5n3W43q8A7\nlZyeLX+qBnFtBPGvDFb1U6mfz8/P9vj4mNXR83GxWLhVZ5yJ5xWh1ClBpwyqKnvlsSmvvpkdSHy1\n8bnkliX+KVL/s6r8Qfwzw6v24nOV9FzS+fLykqn3npr/+Phoy+UyKdE/kzp/DLziGS/7EFqNXodU\n+u97iKkbapVVJwTxL4Cifz5Ld22UgSP60iPPnhtWaoptnW+uU6B5DtwGu9VquZmLnL1oZm4Ck6cZ\nnZqu7H1GTa2u+2YcxL8AUtJov9/n8uzZnlcpD08+bl7NBuPX/mrQGDt64ZnZQR08riNGYLVarey6\ncRIT5zN4myfe95jPp4VU2vDDe4+6IIh/ZqRuCpx7BTZw5D08PGQTaDh+X0XifyWoNIUajo3TIz7s\nehAfyUy4doh2pKT9sdeQ/89K+hT564Qg/gVQdFN4qj478p6eng4y9Xh6K/d+/4rk99ToFPG5Dn44\nHFq/37d2u11I/PeSvkzap0yKuv1/gvgXAJNem15w4Qir+g8PD/br1y97fn4+aK3lpd5+Rm99VbCq\nzz9LNSKB5x4jrFTV5+unptKxaj5/Pq2eTBH+lPe4NIL4Z0bKOYUbTxs0ssT/9euXzedzd7QVq6r8\nXnz8KsD108edTsftdQfSoxzXM5NU/T6Hms//Zx1KGqp+A8ESi6U9Z+qlVP3n5+dcZxxddbuBzg0m\nlD4G+Zn4THrE5bGpXsLG5832GK9+3f5vQfwjUfYPBOG5aQYXzWj+PdfPQ0rxDXNtD35RPDsV79aY\nOcfItVkmJ76k3jP1u1arlUn1/X6fmU7L5TL7eavVOqhuREgPkr+q5937HF4ikaYQ4+ecJBQJPF8U\nuGm4J5tWzy2Xy0y6c5yec+zLYvT7/XXmrylBq1aaMSFACn7MKbKpBBrd8PjY7XYzD36n08l6GCwW\ni+wagegoXOJ+Btpq29OkvM8G8iJDcDQaHTQB+fbtm93c3NhsNrPJZGKj0SirE8D3rguC+O8E3zC4\nQXWMFRJM0PP+9+/f9vj4mFXb6UTZMqfQNclfpcyUz9EMM7XQAJM1AT6HxqTecTyG1O/1etnzUWO/\n3W5tv9/nNCw9stRXZx+us2b58WMQH519QXy0APOIzxteXRDEfwc8YsLRo0k68N4jZv/4+JhtCkjQ\nKcq19977UjdSStp5qroeUSKLtte8RqNRFnLjPHk+B4GLHJz8veHpR0stTonm0mR9DU/l5++vnw1q\nO2oDIPHR8BPS/ubmxiaTSUj8rwolPY6exId6jwo7b2y1Eh+vWbQJXIP8nmTm3+Mcx16vl+uAy+2v\np9Np1nveW+12297e3nJSWqU3VyEWLe957OBLOeBSxUGQ2ilVHxL/27dv2e+C+F8UHvnVxtdwHUt6\nDjnhpvRs+iKH4iXI70n8VGGLbgSQ+JPJJJOCUIFvb29tNBodzL7j891u504I4iPPB+BsSDaZyuLr\nujwHJXf25YpAEF9Vfdj58EHgGMT/IlC7HseUjQ/i//vvv1mFHS9NydXX1ff0Ps8lbiqtZisiP1av\n18sR/+7uzu7v7+3+/t6+f/9u4/H4wOHHj3e7XbYhcrsxHVMFwsPGx+/W67VL6lQIj/9vLPG1/p9b\nZrPE597+t7e3NpvNDmb6BfG/EJT8fAN5Nv7v378z4ntOp1RvvGPiy+e8sTyJ77WqUh8Ahl2g5/3d\n3Z39+PHDfv78aT9//rTpdJrrhsMLzTE4zKkLI6oQxmOv/tPTUzYwxNOavA1bz73vrD3+iiT+bDZz\ntZkg/hdCSnJweq5m6r28vOQcTUz6ayd6ePFzTKtJLQ7HefH66XSam2wDSYilxOc4eLfbte12m8Xp\ncS03m00mNdnPgOQZ7aF/yvfHOY++QiowRyWm02nmvMNSB2bKcVknBPFPhKcmqkrpqZtlHnvc9Mfi\nGGlSZKdrOE5vfE6U0eScdrtt4/E4U+vv7+/t5ubGptNpztGFkB7eF76RVqvlzp73ZgmkipeqXL+U\nfwKmCqvzKPfFOTayb9++ZZ57FAhxqPLUzj7XQhD/BGjaJh89B1KK9Oci/ymkT2XXQVWH9NIj4ude\nDL7VatloNMo580D88Xic2bsaIXh7+2+ohWpKOiaM5wFqOq6G44quX1GoEio92/CQ6vBbgPj4XuzA\n89p56UZTBwTxT4RK/JQTSR1KXoroe8h/ys3keeuxdCDldDrNFhxXRQk4w+EwN70Wr8HJLEw4fH9s\nmNphh1uTIQQKh1/RpKDU9SuKVrTb7ZzEZxves+VBfE/i66ZSNwTxj0RKapdJ+1ReeJlkKvv9KVDn\nFSepqHNO7fXhcOgSnzcOL3EHyTsYYeVdUzMrbECakvipuQFF108/N0/j5QQdkJ3DdViapFM1JbkO\nCOKfCE/iF9n3ZWp+6gYtklyngG9Er3stT6K9ubnJhePu7u5sPB67dizOeayVjrHi/PqUj0RtfE/V\n9xqUpJpd6PVLRStAfFb1IfGh3kPFZ02IJX4q6lFHBPFPQMrGP2aV2fkM7+Z9D7xwFU+iZYl/f3+f\nheN+/Phhk8kkGd/3El40Zt9qtTJvvGpF6qFnic+qvo4Jg8Q/5vqlNj9W9ZGZx6O4v337dqDNsKrf\n6XRy/yM91gVB/BNxjMRPSf1jgJv3HKT3pB3HqlXi//jxw/755x/73//+Z9PpNOfA8sJWKY8/vgMa\nZ/IGyg1LvDAoS3xvjHhK4uv1w7n3+TmMx34OJT5affHgDg434j3qjCD+BYAbi28mTgBRx9bb29uB\nI+hU9b7sOfzZ8Jn4s0G9ZYce2/qz2axQ4jPBPFOGJbu3tD+BZu4tl8vcJCHunMvfP3XU/4nmErBT\nEgs2PVR8DXNyiLJu8foUgvgnQO1EvsGhLrODCARaLpfWarUOsvZAFs7cK9oA3vvZ+TOq9IIDC4kq\nqfi7Z796yUx65HCdd0SWI2YLaD1DWScdMzvYiPicx24xeXE+nU4zf8bd3V0uHIlr4XX9qbM97yGI\nfyJwQyk0p5vjv+v12swss19ZQkIKKuGPjelX+dyQ9l75bKqmXDPnlPycPMM2vB63261bcIP1/Pyc\nIz43K2F7vqyWPlUByCm32Ow4SQcmDq4DJD078VhTqGM6bhUE8Y+EF6Zhu04l/mQyyXV7NbOMRGb5\nij7eCDxCnevzK/FZrWeJj5s9RXwFhzW1mQa3F4fKzkecPz8/Z/0KvGlCXk87tu89M4udi7rZccot\nknVAds5D4GuhKcyakPQZEMQ/EUx4vuk8iT+dTnPNIvB3bO/q1NZzq/j8uXlzYs817Hjc+JD4XGGm\nziu+2dnR6dXGQ9qz/c4jsNR7jxRdaAdQ9VMltdgk2YehfgxI9aKlufhY6r2vc0+9MgTxTwD/k2Hj\nQyqrxOe+7gg5sXoPmxf2M7/+uaU9Xpslvqfewq5NqfpFUImvnXAQl+emo14DUt4QUjF7PeL7scRX\ne5499ey406QcL09/OBzmUo4/q7Q3C+KfBP4nqxdbQ0Je9R2r917lmar6+j7v/exs62qsGhV0sGtT\nxNfPwl579dyz807j8joVmIdhsDnA5cua+ejZ+Bye5GQiLymHawsmk0luo9Aj/5+8eofPgiD+iUip\n5eoxZ9LjudylZ7Va5YZBeK95TqnParCq+vBic1GKZ+OzJqIhO/beQ73nFlos8bkHIRZ6EOL5mqwD\nrako61FtfKj4HJtHjgIyE3GcTCbJ5CNIe/xPvONnQRD/SHj/YFX9mfzsfTazLIElZQMjpZWdV9ea\nweaF4/D++Kx4XirtFnZ8ajHhuQEpJP5isXATdHjzVIcqL+755zX85G643kJKclFfwK+AIP6Zwapm\nv98/KCABkdgRxRsFGnV4Nz9aTb0HeH+2t7ntNboHcR96blzZ6/UKe9dtt1u3Vx7OX15eMucdyO5V\n2/FmCTu62+3afr/PFRXpEVoMay3ssYe0T7XB1tz9zxijr4Ig/pmhNuZgMHCTcrznjUajnBcbhIF6\nDcfWe4DXAfHn83nOsYg8eY/0u90u64uHDUQbWXJxjbd01gCOXG3nheg4B75oYAfs+NTySoY9b/1X\nJr1ZEP/swE0KKc7ZZOoY8vq0c385HhqBgZvvBb8WJDBID01Ap82w1oK+eN4kYMTpNUZf5QgHHufd\n48iqPa5ZaqEfAEjuHVUT0MEXmvmXylT8zAjinxksyVnScxUcq/fIHoOTDTYwcvqZqOewLzltlrUJ\nkF4lvY6YQl88zz+Bz8m59bo4mclz4sGPYGYHEp/r5TXdWPMmOCbPj5GIw5l7nJGnSUqfzVtfFUH8\nCwCdYM3yXnTO8dYkH0i/yWTiSvrFYnGWG5BVfSY9nHI6tIILYMz+El8XNgsupdUW2S8vL7mNxZt0\ngzZcqcVmETf5wLl2DtJztA/ztIXP1EjjvQjinxks8VnSg0C4yfjm5cGO8CqbWa5NN9vh7wFvJkr6\nXq9nq9XqQNJD3YZ9zeaAmgZwGOpi4nuz8fj9tEttkWmk9juTXG352Wxmw+Ew139Ajyzh+RjEDxSC\n1UNIfl7D4dA2m0121DUajTJygvTPz8/W6/XOcvOxV59Jjxt/tVolJ8hiQ9OxVnwOhyE77/gckYlU\nJV+7/d8YLWyc2HS0UYb2tU+V0+rjwWBwUGeRkuxfjeyMIP6ZUSYddrvdgfrPau9+v881nuAuL4PB\nwDabjZnl+9RpIk0ZeCovPg8WSKfebRAExPdIzwk6PEeAH6MCURcku1cvz+bRaDRKElulu3fe7/ff\n9w/+IgjifwAgabABMGk564/VWdzAZnYQRz8mwUfTgVni4rV59h9nq729vVmn0zlQ7/kx5wBo4g00\nBi8phiW6jp/ic9QWFHnt2VPP3W8DfxHEvzJUyqm0LiL+dDp1M/9ardbRMX7WFtABiM0AOBSZ9K+v\nr9bpdArHWHOHXC6qMbNcMwxPqmNpcww+4poULS6qUadd4D8E8T8AkPhwZOFnIEWK/LPZLEuLZWlr\n9rcGoIrK7xX+wJvOEh9E5RAgsvuKxlNrqq1HfO68q91wdNosd+r1Jtx44Tn8DQ/xCOL/RRD/A8DE\nx2P8rEjiLxYL2+/3tl6vc3njkNTH3thaxw7NAQ4/vDaX1LbbbbfRhv6Mj5rPoF1wtAy2qEOObhja\nyrssTBf4D0H8K8NzaIH0CPeliI/psHwTcxFN1RtbK9vY5ofEx2tD0iPcB+J7/gVuheU1ytDEJXjm\nNZtOY/P8GJWC6gPQPAlN6Q0bP48g/geAJT6f7/f7JPGRyw573CzflvrYGztVT29mWb48SM+xbjzX\na4RR5mPQgiRt+8XZdbqwKWjrK2+arzoMOR8g8B+C+B8ASHmvplyJz+RHjN3scET0KTYsq/r4XJDa\n0CA0zs1/q3/PG5l2uOUKO+73hx53PJOuqMiGJ9Z4BNfCmq+cffceBPGvjLIEEY7vQyrqVFiW9Gjb\nBYn2nrLdc3X40e6zHMZjNZ/NmCLic4YezyXwNpggdzUE8WsG2P6aoabtu9j7juKSj77pkXmniTgc\nutNwnKbaYrJuWQ/7lCYSqIYgfs2Am1rHNXO2HTvc6uK1Zm3Ba32FIxx2qTx7JN9w1Rwn4Sjpzb5m\nLv2lEcSvGTyJzx17EMdHZh283B/ptfZy+lMNLz2Jr+TXMB2Xy37lGvlrIohfMyjxtU3X29tbVryj\nHXA/ggSeX0BVfS9SwaRnzz7Kkr0QnfawD/KfjiB+zcCkGQwGueq0Xq9n+/0+16mWG0hcmwAp0nuq\nvhep8Mg/Ho8LY/EpFT/IfxyC+DWDktzMcjb/29ubzedzt2XUNW/+ogiAJ/GLSK/EL+pwq+2t9TxQ\nDUH8moGJz+fcEQftubjn/TVDWWWkVxufU2rZucdefRzH47EbquNj4P0I4l8ZqUEQXCzDyTGc0qv1\n8R8R0qoa6/dUcP4uXJasoT8vXBf2/HkRxP8AeB1oOD6fGrjx+vpqLy8vWfou98fzavGPUYdThPZe\ns4j83OADYUd2zg0Gg1z7bq+bL96DJX2V7xCojiD+B0Dz27mYhUtb+RwL3Ww4m49LX83S45005ZbB\nhTr8HO/nVcgP4iOlGNoKNq0i8nPtArfVDpwPQfwrgwtcvAo3rmf3OtxUlfhlIa/UJuCRmnMIip6H\n57LER84BPgNLfO24q1OH+H246Wfg/QjifwCY/FrHrtNl+Xy9XhdKfCVGmX3sNeTg3+HnKZKXkR/E\nZ6dcv99PSnscWbp7BU2B9yOI/wFQqch2vU6XZekI4nsSH1V7Zj7h2VbGZ2A1vohcRRuE/kw3NDTX\nxO9A/BT58T34M2t7ssD7EcS/MlTVZ5UYzjBuVa3TZsskPqCE58dK9JRk59/zY4X+HX8v/RlLfE/V\nx9/gs3L/gcD5EMT/ALAHX6U9N6v0Js4W2fiAZ9+rdzxF/tTnLYPa4uyd5+/qqfoq8Tk9WcdxB86D\nIP6RKPNm46iL6+iL2lPztFkmPB4/Pz/by8vLQRdbTvbRJhV8ZIKnQoqe01FHaaVsfvwOfw/g7/W7\ns6TnrsGI8wfpL4Mg/onwVOKUw67IeadOPLbr2RbGOcZML5fLbBpOq9XKWlp5dfCa766hRN2YNHdA\n4+xmxeq/biLsVNTGnN7i5B7dcALnQRD/BHgSE49ZomsbbHXcpVZqSg1q8KEBgPhmliXH7Pf7rIGF\n15ee++erNAcZdVMCcbmTb1UTAeQHvHl53kaJpp7e7IHA+xHEPxEpNZmbZLCk5lUk1WG3qxmgJoFO\nl0U1X7vdLmxRze2xWTvBQhvt5XKZaQggL7f+SkUEVNrr9dL3ZEnPjUNZ2gfxz48g/gnwbHd2YoH4\nqfnw6q3nxxrX1hg3CMIEMvsr8bvd7kFnWj7vdDoHROPz9Xqd63jDMXmOx5cRUc0f1hq8Hvy8Op1O\nLlIRdv75EcQ/ESmHGA+kwKTb+XyeDcFk8ntOPDjsUsMpNMSG8273v3/lYDA4mBHPjS5A/JQNz5Le\n7G9vfUzW4fdOxf81tMdhxKIBHDqgw3MqBs6DIP6RUKcek1774WHq7ePjoz0+PtrT05PN5/Mc+XGO\nI3ras1Tno5nlesjrEUMlMU1WV7fbLZx9h3l5ICn8Eqia41AgXw9V9/kacdZgyrbn1e12DwZ0hLQ/\nL4L4J8CT9OwgY1UftfMPDw/28PCQSf3Uwvx49bbjHCo9HHaQ9vg5z9m7ubmx29vb3Or1eoV+AzgI\nWfVnLaBq0Y5HfjM7IHuRvR8x/MshiH8ClPDqHIOjDpIcav7T05M9PT0d2Pz8eLvdJkOFZn+lvVl+\nMg2627BaD6l/c3OTbQKQ+KlcAvYB6HcZDocHIUDdoPQ6ed9DowhahdjtdnObQkj98yOIfyRY+npO\nMvXke2m3mqqqKbdFZbU8hcZbkPSw8bldNZx/HCfHRoAWWWZ2EIJkHwAcb+p/4J7/Va8f+0R480He\ngRI/cD4E8U9AKs8eTr1UGI9Tbb0GFLjBObdez1m6Y/Yct6+ClAfx0eoKPeo5sw8E4+9gZm7YEKvd\nbh/8DOZJ1So6L9GJid/r9XKpyEH88yOIfyQ4bKc59iB+Eek94ntSTVtsgazcu05bU4PsfO5JfKjz\nXnZhq9VmRwyyAAAPiUlEQVRKptIipIeEIh7bBeld5fp5GycnDEH78Gz9wHkQxD8BfOOqmupJew7Z\nIVZfRHyW8NxlFkk6PGJaPfjoTa+TZ5n4u90up0pz5ECJr5sAzA0mvZbfloElvm6em83G+v1+ZgKF\nqn8ZBPGPBEt8lVgpaa+L1eQU8Vkd55CdDqbggZM3NzeZlOfEHZX4Gong1W63D8wX1g5QDMSSfrvd\nVm6NpdfP2zw9EyjIf14E8U8AO6a0ht4rrOEEndVqdaA+e1JNyY8iGx5DhZ707L2fzWaZD0DXYDDI\n5b572Ydsw3uqPsDmzrFjuj2J75Xopq5N4P0I4h8JlVggSaqyzlteEgtLXC5LZeLzIE1P1b+9vbXp\ndJrl5+tCKi6+Bx9xzuE83ZzYc8/JSscM9EjZ+F6IMaT95RDEF3ixZz4H2Vm1XywW9vLyko21Qpou\nd8thhx6r1qzeo2Zex07xAEm153nBruchlUj24ZFURXh7e8v9rW4e2OCKZtqd6/p7jwPnQRDfgarC\nvDgrD4k5IDqSdP78+WOPj4+59FxumqG2PDecQJEN1HkO3Y1GoyxOzwtOPB4rraQ8lpjauUcHeqQa\neFZ5XdVmeNSWfvZzbiqBvwjiO9CUWZbOSGEF8Z+enrI8fByfnp6yDcHrlmN2ONOdu9B6o6U4Tq+h\nOyY+Rmq9RxqnGnV6Y63eQ34QG5+X+wZcQpsI/EUQX+Dl4LOtqQU4kPB//vyxh4cHe3p6ytR+bYyJ\n1+EqN03QQYwe3npeILwOnMTiIZocDdAps1Xh5RK8l/waqsTnhLRn0r/38wfSCOI7YPJr+ShLfFbt\nf//+bb9+/bLn52e37Fb743kqdKfTOSC+FtlMp9Ocp56n0ELVT02arYoiie+p+8fCi1ioqo9cAZ2S\nGzgPgvgONNykYSe28R8fH+3Pnz/269cv+/fff+35+fmgdRWOqKdn0mhpLcJ1sOXv7u7s/v4+W9Pp\nNOe003O1609VlctI7w21rPq6utmlbHyuKwhpf14E8QWq6ms+PkJ1qur//v07I77X4AIbCN7DzFw7\n15P4379/tx8/ftiPHz9sOp3mGmhqM01VjY9Vx4ts+yJV/xh4Ep9VfZBfnXtB/vMhiO/Ay84DkYtU\n/X///dfm83lpZpx69fnmV+JD4v/8+dP++ecfm06nydbZrBKnKvyOQdkG4JkEVV+3ilc/nHuXQxBf\noCW3IDsSS0B6OO7YkYeF19HXhWrPJOdY/XA4zDLwPMfet2/fbDKZJCv3zi0VixqOaCPMqkU0KROC\nTZ6USRE4H4L4Ak1F1Xp6bZ+FrrjcGsvMkjYwymo5Vs/nNzc39v37d7u7u8uIDqedp7Zfguypyrmi\nkmLOBAyS1h9BfAFXm+Fm5w45THyutOPknCK7GM0wtY4eR26XBeKPRqNcRdyp8fNjrkEV8qeKaIrI\nH+W19UAQX5AiPjrlgviYYccS36uu0zUcDjOiswqv51gs8Tksd6kNoIj0RTPttRNumeSPDeBjEcQX\neKo+Z+mlVH3NylPnFRZUek69vb29zY6op2ctYDgcZp1zVM0HzkV+zWHwyo5TvQRSfo2y9wtcH0F8\nAdeYe6E7VfXVxtdQHYfder1eVlUH6X53d5d57u/u7rKyWp2AA4mfIv45kaqc86R+Wels2Pz1RBBf\nwKq+JutoDn7Kucdeaw1VsaoPKY84/ffv37PqOoS1NJNNM9jOTSpP4hc596rUy1dR+wPXRRBfwKq+\nV5BTpOqnOuhwAYqq+nd3dxnx//nnH5tMJq5v4Jrx7CKJfynyB66LxhG/SvvnIvu2yo3PqbggvrbM\n4tZYXHWXitPjcep7VJWa7Hn3zsvahp1C+kD90DjiV0GqNZU3QEKdWpyYwqTnphacX89z68vSa5Wo\n3qry3bTikNd8Ps/6CWhDkVR78CrkD2lfLwTxzZ+HlyK9l7GmYDWfbXutotO6+SopsPqZdEMqIz+y\nElMDK0F8NmvUmXlu0semcH00nvhFpC9KV02pymX2PUt9boml5aee514/E0vtqio39wn0VhWJr00x\ni943SF1PNJr4Snr9XVF+ekrCesRnNR/NMljVTznvlPStVitHeq8vvibSKNBTQMuGcY5SY+4kxMSH\nM5MlfmrTqVoNGLg+Gkt8j/Seip+S/CnbWuvsVeKzqn9siylP4qvKXkb819fXQuddkcTHc8pag+M6\nFCEKbz4WjSU+wKTHMUX41IagN31K1edutdobL9VwokgT0dHS6OBbBIz54km9fITEV+JzN6GUxgEU\nEToIXw80mvhVSe+R37PzzQ5VfSY9D7YosvH5NaHe8+djtV7j7WXER2hyuVy6JcWcqMR1CazqF5k9\nQerPgUYTn1Gm+nuErxo+81R0ToxZrVY2GAxssVhk02q8TWW//y+5iItkdKQ1uvykAAeeR3qeDeDN\nBcB7pjbHFNRvccziv49N5XxoJPFTTj3Pw8/nHuG9x5zqCrVaB03yBsBZcb1eL/n+ZnYwYJKJv9ls\nKqn6KDFWVV8XE56990VmDuA5KZXURV18owHHZdFI4hchRezU8v4eRT4g9HK5tG63m93EqTr35XJZ\nSHyW+KlVJvFfX18Pmot4M/44dKdFSFW1Ha9ZSBnZU/kMsQGcF0F889NdywhfRHyV+Fxc47X1AuEW\ni0Vutp1Hfh3SqedlxEc4zwvlcfUdpH1K4nufEfA6BFWR8tpyK6T+5RDEL0EZ2T2CgtybzSY3TJJJ\nr5IehUAe8fm1UTzkkRZdcYqAoSBe8o76C7wBlp75gceKlOTWTr1VSB/kPy8aS3yPwDhWIXlViQ9J\nD9LydF2QnpN7MGe+jPipVSbxefPRcKA+1hbhSnzvOgIe2fVYxb4PiX8ZNJb4HqoQ3SOjAk47lvRs\nm6/X6yzEt1gsctNpMb8+9f5MfFbH8biM+NiYOCSXeqxHj/jeNUip+SnCp9qEHzsTIFAdjSZ+SloV\nefT577wjq/pmfyXsdru1brebjZhOLY3je8QH4blUFscyVV9ft+g7lm10RQ4+Jv8x0l4HaATpL4NG\nE9/Mb/qYijt7N7AeOamFJ+ewis0efW7Lhb56RQTkaT6e5C+T+OdAUdy9TIVHH0G0FOeCJW88dkj9\ny6DxxAdUsrEE0sGObAv3ej17fX3Nblj8Ld+oIH7qPTkFlv/G2wDglfds7yIJfC60Wq3crD/vmOow\n3G63bTabZW3GMDsAY745jTnGZF8WQXwHXGjDU15wQ6oDjLvo4u/ZqQfSe55wLbbxVH0+17Jatr+v\nAa+PoDfzLrUpTKfTXHPRm5ubjPjcp0AlfxD/vAjimx+P1px7JT5sds61Z8ecltQy+flnnU4nIz2H\n/sr8B1oWew1pj+/V6XQOSo1xrrPv9BzTgtBSHMRHDQPqF3DdI55/GTSa+Cn1WG1Vlfjb7TY7qkRL\nxbeZuCzpdaS1FuXw0czvoKMe90sCqj6PAkPfwMlkcqCus4mE9uLoL4jFqj4PDgmJfzk0lvipGLxZ\nvj22J/Eh9Zn8WExule77/X/Va29vbxnZod5z9x39fEp8r/vOtSQ+VH1uFY4pQJgJoKo/P8bf8IaB\nxqM8IzAV2w+cB40lPiPl2Wepo8RPqfrwqjP5OUaO1y5aRSEz3ViOzZ9/L6DqQ+KjQzBUd0h9lCPr\nkUuUuT8BVP1er5dM/gmcD40kfopYLPFTar4uHZHF4TSV+FipyrWiz1n0ea8l7c3yqj5L/NvbW7u/\nv7fpdJojOCcnceehIsegd02C+OdFI4nPUlXPQXr2XEMioQlFUewaZkAqHTZV6KLOPz1PfQ/vsVck\n4z2/6DW9BJpWq2Xj8Tgb6AnnHM8ALCI+O+9SDkCERAOXRSOJb/b3BofdDYC8UGV5Em6r1co2gvF4\nfFDL7jWj1HOvOaamzCpSDkiP3FUy4squi5dGi+N4PLbb29ts5h/Ob25usoEgLMVBdvX2q+MuvPbX\nRWOJD+jNBtV+MBjkSI+bH00zl8uljcfjXP06iO81yOCqN80D4GV2KPXV7i/LnONIg56XkQsbn5ow\nPO0XEp6lPhx84/HY9ebz0sy8sOGvj8YS37vRQByW+Pg5VNLhcJhV1XHzChx1oqxXOqubAT6LFsGo\nVqImiTq/+HOmVpkqDccde+P5HOG46XR6EJKbzWbZSO9UHJ9JrxI/cD00kvhKIv4ZS3z8HGQYDAY2\nHo8rzZfzCmj4Z3jMpEeuP6Dk1+/A/gVW0bmzr3rWy4jf7XZztrmee7F7Ds+hwpDVeS8hJyrwPhaN\nJD7g3WiQ+Pg9SI+bXqfGKpG1hRWfg3zL5dJt0MGlvECK8KmCGG+IBy+kFaeAJBuE23BetvBcxOE1\nMcmT8LxhBa6LxhLfc+5p+Aik51x6NNHQVlVMfnX4oeYePfWU9Mi/B1G8op4iB5+GHzUagUq48Xhc\nSvx+v5+T4Jpow+3BPY89x+FTVYxetCCk/XXRWOIDesPh5uT0W62i83rdYaFf/WKxyI7s2dZ8fM77\n73Q6mYNPVfyUjZ9KLYbEV7Uc2kwK/X4/s9mx+LEO/PTKinUjTR1T/4PA5dE44lcJZxVht9sdVKex\no07j1Hz0wllatrrZbA5y+jXl18tlx/lgMDiwv3n1+/3C79fv93NkZ9LPZjMbDAYHGYv8ONT2z4HG\nEf8c8DL7AM2dTznckO4KQkFDAPGLUnI9+xnn/X4/p9rjiPMyid/r9Q5Uezj4vBh8eOU/J4L4J4A9\n6F4uvT5H5+chD2A6neZyADBJp4j4KaceZw5qDvypzj0d8qnNMbziosDnQBD/SLBtrcRX55WSHmm/\nXlSAe+aluu+wFsEOMz5HKDJVIFMlnMdhPK81ViocF/g8COKfAJBsv99n2XBse3uSXvvXa2afTsLx\niK/v7yXx8Pt6NfFl0hnmgldSi4hEKgYf5P88COKfACYPEw9JODwpV5tmpHrWV+ldD1Vfw2Beyq7n\nfOOJPkXfrShlF1GJIP3nRhD/SOAGB4FY+mv5bap3fapIh52CKd8BfwbvqJqHOgCr5OoXFelouC5I\n/zkRxD8BuNF56g1QZp9rbkDqead8Hj4/NUkm9XcpkgfpPydaV2jicL0uEYFAQOHuzBGHCQQaiCB+\nINBABPEDgQYiiB8INBBB/ECggQjiBwINRBA/EGgggviBQAMRxA8EGoggfiDQQATxA4EG4hpFOlHF\nEQjUDCHxA4EGIogfCDQQQfxAoIEI4gcCDUQQPxBoIIL4gUADEcQPBBqIIH4g0EAE8QOBBiKIHwg0\nEEH8QKCBCOIHAg1EED8QaCCC+IFAAxHEDwQaiCB+INBABPEDgQYiiB8INBBB/ECggQjiBwINxP8B\n7kSDNKPylHIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a6a5f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.cm as cm\n",
    "\n",
    "images = data.iloc[:,1:].values\n",
    "images = images.astype(np.float)\n",
    "\n",
    "# convert from [0:255] => [0.0:1.0]\n",
    "images = np.multiply(images, 1.0 / 255.0)\n",
    "\n",
    "image_size = images.shape[1]\n",
    "print ('image_size => {0}'.format(image_size))\n",
    "\n",
    "# in this case all images are square\n",
    "image_width = image_height = np.ceil(np.sqrt(image_size)).astype(np.uint8)\n",
    "\n",
    "print ('image_width => {0}\\nimage_height => {1}'.format(image_width,image_height))\n",
    "\n",
    "# display image\n",
    "def display(img):\n",
    "    \n",
    "    # (784) => (28,28)\n",
    "    one_image = img.reshape(image_width,image_height)\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.imshow(one_image, cmap=cm.binary)\n",
    "\n",
    "# output image     \n",
    "IMAGE_TO_DISPLAY = 10\n",
    "display(images[IMAGE_TO_DISPLAY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a \"next batch\" function that will return X image-label batches\n",
    "def next_batch(c, last_index, df):\n",
    "    '''\n",
    "    c: amount of batches\n",
    "    last_index: the index where to start getting the c datapoints\n",
    "    df: dataframe to get the data from\n",
    "    \n",
    "    returns: tuple, where \n",
    "        index 0 holds c arrays with 784 pixel values\n",
    "        index 1 holds c arrays with 10 label values in one-hot format\n",
    "        \n",
    "    This is built to work like the 'tensorflow.examples.tutorials.mnist.train.next_batch' function\n",
    "    '''\n",
    "    temp_data = df.loc[last_index : last_index + c - 1]\n",
    "    last_index += c\n",
    "    \n",
    "    # Output has to be\n",
    "    # tuple-> ( \n",
    "    #  np.array([<arrays of pixel values per image>]), \n",
    "    #  np.array([<arrays of one-hot target values>]) \n",
    "    # )\n",
    "    \n",
    "    temp_pixel_data = temp_data[temp_data.columns[1:]]\n",
    "    temp_label_data = temp_data[temp_data.columns[:1]]\n",
    "    \n",
    "    one_hot_label_prior = temp_label_data.as_matrix().flatten() # will give us a flat array of labels\n",
    "    \n",
    "    count = len(one_hot_label_prior)\n",
    "    one_hot_label_final = np.zeros((count, 10))\n",
    "    one_hot_label_final[np.arange(count), one_hot_label_prior] = 1\n",
    "    \n",
    "    final_batch_out = (temp_pixel_data.as_matrix(), one_hot_label_final)\n",
    "    \n",
    "    return (last_index, final_batch_out)\n",
    "\n",
    "# Let's do 2 test outputs:\n",
    "\n",
    "curr_i = 0\n",
    "curr_i, curr_batch = next_batch(4, curr_i, data)\n",
    "\n",
    "\n",
    "curr_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "curr_i, curr_batch = next_batch(4, curr_i, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's get a sample and render it\n",
    "_, batch = next_batch(1, 0, data) # get first image; we don't care about our index-increment here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_sample = batch[0][0] # get first tuple entry and first and only img pixel data array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_split: (33503, 785)\n",
      "test_data_split: (8497, 785)\n",
      "train to test: 79.7690%\n"
     ]
    }
   ],
   "source": [
    "# split data into training & testing sets using a random boolean mask\n",
    "msk = np.random.rand(len(data)) < 0.8\n",
    "\n",
    "train_data_split = data[msk]\n",
    "test_data_split = data[~msk]\n",
    "\n",
    "print('train_data_split: {}'.format( train_data_split.shape ))\n",
    "print('test_data_split: {}'.format( test_data_split.shape ))\n",
    "print('train to test: {:1.4f}%'.format( train_data_split.shape[0] * 100. / data.shape[0] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's lay out our parameters\n",
    "learning_rate = 0.001 # the lower the higher possibility for accurate training result\n",
    "training_epochs = 50 # how many times we run learning. higher takes longer but yields better accuracy\n",
    "batch_size = 100 # batches of training data\n",
    "\n",
    "n_classes = 10 # there are 10 numbers: 0-9\n",
    "n_samples = train_data_split.shape[0]\n",
    "n_input = len(train_data_split.columns[1:]) # label column is no input\n",
    "\n",
    "# Count of possible values for our hidden layers\n",
    "n_hidden_1 = 256 # possible pixel values (8-bit colors)\n",
    "n_hidden_2 = 256\n",
    "# Now create our variables with randomization\n",
    "weights = {\n",
    "    'w1': tf.Variable( tf.random_normal( [n_input, n_hidden_1] )),\n",
    "    'w2': tf.Variable( tf.random_normal( [n_hidden_1, n_hidden_2] )),\n",
    "    'out': tf.Variable( tf.random_normal( [n_hidden_2, n_classes] ))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable( tf.random_normal( [n_hidden_1] )),\n",
    "    'b2': tf.Variable( tf.random_normal( [n_hidden_2] )),\n",
    "    'out': tf.Variable( tf.random_normal( [n_classes] ))\n",
    "}\n",
    "\n",
    "X = tf.placeholder('float', shape=[None, n_input])\n",
    "y = tf.placeholder('float', shape=[None, n_classes])\n",
    "def multi_layer_perceptron(data_input, weights, biases):\n",
    "    \n",
    "    # LAYER 1 with some more explanations:\n",
    "    \n",
    "    # INPUTS * WEIGHTS + BIASES\n",
    "    layer_1 = tf.add(tf.matmul(data_input, weights['w1']), biases['b1'])\n",
    "    \n",
    "    # Activation using RELU, which is just f(x) = max(0, x)\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    # Layer 2\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    # Output Layer\n",
    "    layer_out = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    \n",
    "    return layer_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct the optimizer, which will essentially tune weights in our perceptron\n",
    "\n",
    "# Instance of our model with variables and placeholders\n",
    "pred = multi_layer_perceptron(X, weights, biases)\n",
    "\n",
    "# cost function, we use a mean over the cross entropy\n",
    "cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits( pred, y ))\n",
    "\n",
    "# our final optimizer. AdamOptimizer is quite new. More here: https://arxiv.org/pdf/1412.6980v8.pdf\n",
    "optimizer = tf.train.AdamOptimizer( learning_rate=learning_rate ).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. epoch with cost of 53659.67409048506\n",
      "2. epoch with cost of 14766.505730381301\n",
      "3. epoch with cost of 9201.76233019473\n",
      "4. epoch with cost of 6446.691996833463\n",
      "5. epoch with cost of 4658.72544296037\n",
      "6. epoch with cost of 3452.2342145094212\n",
      "7. epoch with cost of 2572.4844423151744\n",
      "8. epoch with cost of 1912.907166629052\n",
      "9. epoch with cost of 1420.896105921447\n",
      "10. epoch with cost of 1048.1081826452\n",
      "11. epoch with cost of 804.3646602334372\n",
      "12. epoch with cost of 600.9037010762227\n",
      "13. epoch with cost of 443.77731292244874\n",
      "14. epoch with cost of 332.97188333579874\n",
      "15. epoch with cost of 272.54872485879656\n",
      "16. epoch with cost of 213.7219982805536\n",
      "17. epoch with cost of 180.7914135021949\n",
      "18. epoch with cost of 141.07541294133486\n",
      "19. epoch with cost of 130.6873433511648\n",
      "20. epoch with cost of 133.25711613840133\n",
      "21. epoch with cost of 108.58903994987263\n",
      "22. epoch with cost of 87.13348291374515\n",
      "23. epoch with cost of 94.2343515015805\n",
      "24. epoch with cost of 129.5498562382228\n",
      "25. epoch with cost of 127.39785520959255\n",
      "26. epoch with cost of 83.18069564210833\n",
      "27. epoch with cost of 72.41860692403212\n",
      "28. epoch with cost of 111.43810063440414\n",
      "29. epoch with cost of 73.56871310561448\n",
      "30. epoch with cost of 101.19950364934863\n",
      "31. epoch with cost of 105.54915029241965\n",
      "32. epoch with cost of 71.29746910209084\n",
      "33. epoch with cost of 102.52641318129074\n",
      "34. epoch with cost of 65.05043725611559\n",
      "35. epoch with cost of 44.79509726709394\n",
      "36. epoch with cost of 72.00901058325125\n",
      "37. epoch with cost of 60.89450747077144\n",
      "38. epoch with cost of 80.6955769871598\n",
      "39. epoch with cost of 72.08249637013049\n",
      "40. epoch with cost of 87.83000611866711\n",
      "41. epoch with cost of 43.852854572125324\n",
      "42. epoch with cost of 56.62235895555412\n",
      "43. epoch with cost of 61.279541989226814\n",
      "44. epoch with cost of 64.05444836545345\n",
      "45. epoch with cost of 54.829806599688176\n",
      "46. epoch with cost of 55.90181157197526\n",
      "47. epoch with cost of 58.566326900026695\n",
      "48. epoch with cost of 41.32975011654753\n",
      "49. epoch with cost of 60.93428788256289\n",
      "50. epoch with cost of 53.19605800998744\n",
      "Training Complete!\n"
     ]
    }
   ],
   "source": [
    "# Create an interactive session, which works best for this notebook\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    \n",
    "    # optional: we'll print out the cost at each epoch\n",
    "    avg_cost = 0.\n",
    "    \n",
    "    # number of batches we need to run to iterate over all samples\n",
    "    batch_total = int( n_samples / batch_size )\n",
    "    \n",
    "    batch_idx = 0\n",
    "    \n",
    "    for idx in range(batch_total):\n",
    "        \n",
    "        # get next batch, assigning batch index to new incremented value\n",
    "        batch_idx, batch = next_batch(batch_size, batch_idx, train_data_split)\n",
    "        \n",
    "        # use tuple unpacking to get the data and labels seperately\n",
    "        batch_X, batch_y = batch\n",
    "        \n",
    "        # run our session with our defined optimizer & cost tensors, as well as data & labels\n",
    "        _, local_cost = sess.run( [optimizer, cost], feed_dict={ X: batch_X, y: batch_y })\n",
    "        \n",
    "        avg_cost += (local_cost / batch_total)\n",
    "        \n",
    "    print(\"{}. epoch with cost of {}\".format(epoch + 1, avg_cost))\n",
    "    \n",
    "print(\"Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94951159"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform dataframe to needed array representation again\n",
    "# TODO should be combined with the same process done in the next_batch function\n",
    "\n",
    "test_data = test_data_split[test_data_split.columns[1:]]\n",
    "test_label = test_data_split[test_data_split.columns[:1]]\n",
    "\n",
    "one_hot_test_label_prior = test_label.as_matrix().flatten() # will give us a flat array of labels\n",
    "\n",
    "test_count = len(one_hot_test_label_prior)\n",
    "one_hot_test_label_final = np.zeros((test_count, 10))\n",
    "one_hot_test_label_final[np.arange(test_count), one_hot_test_label_prior] = 1\n",
    "\n",
    "correct_preds = tf.equal( tf.argmax(pred, 1), tf.argmax(y, 1) )\n",
    "\n",
    "# will give us boolean type, we need numerical to calculate accuracy using mean\n",
    "correct_preds = tf.cast(correct_preds, 'float')\n",
    "\n",
    "# create our accuracy tensor\n",
    "accuracy = tf.reduce_mean(correct_preds)\n",
    "\n",
    "# evaluate accuracy using our test split data\n",
    "accuracy.eval( feed_dict={ X: test_data, y: one_hot_test_label_final } )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions on the test dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First we need our test data\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, ..., 3, 9, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the label-index with highest probability (in our case index = predicted number)\n",
    "maximum_probability = tf.argmax(y,1)\n",
    "\n",
    "# actually predict our labels using the test dataset\n",
    "predicted_lables = pred.eval( feed_dict={ X: test_data.as_matrix() } )\n",
    "\n",
    "# then transform those predictions into our final array of predicted labels\n",
    "predicted_labels = maximum_probability.eval( feed_dict={ y: predicted_lables })\n",
    "\n",
    "# our final predicted labels array looks good\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save results\n",
    "# we need to have an additional incremental id column for the submission file\n",
    "result_array = np.c_[ range(1,len(test_data)+1), predicted_labels]\n",
    "\n",
    "np.savetxt('submission.csv', result_array, delimiter=',', \n",
    "           header='ImageId,Label', comments = '', fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
